import ftplib
import gzip 
import datetime
from dotenv import load_dotenv
import os
import shutil
import xml.etree.ElementTree as et
import concurrent.futures
import time

load_dotenv()

MINUTE = 60
DARWIN_PULL_INTERVAL = 5*MINUTE
RUNTIME_LENGTH_MINUTES = 1
ZIPPED_OUTPUT_NAME = "data.gzip"
DATA_OUTPUT_NAME = "trainUpdates.dat"

# Credentials for accessing the FTP server
FTP_HOSTNAME = os.getenv("FTP_HOSTNAME")
FTP_USERNAME = os.getenv("FTP_USERNAME")
FTP_PASSWORD = os.getenv("FTP_PASSWORD")

# Get most recent file in pushport and writes it to filesystem
def getMostRecentDarwinFile():
    ftp = ftplib.FTP(FTP_HOSTNAME, FTP_USERNAME, FTP_PASSWORD)
    ftp.cwd("pushport")
    
    for filename in ftp.nlst():
        # Stripping out the date time from the filenames - Darwin runs on UTC all year round
        timeCreated = datetime.datetime.fromisoformat(filename[14:-3]).astimezone(datetime.timezone.utc)
        currentTime = datetime.datetime.now(datetime.timezone.utc)-datetime.timedelta(hours=2)
        print(f"Current Time: {currentTime}")
        
        timeDifference = currentTime - timeCreated
        # 7 Minutes because files are uploaded to Darwin in roughly 5 minute intervals so sometimes 6 minute gaps will exist.
        print(timeDifference)
        if timeDifference.seconds < 7*MINUTE:
            print("Happening")
            with open(ZIPPED_OUTPUT_NAME, "wb") as file:
                # Writing the contents to a file
                ftp.retrbinary(f"RETR {filename}", file.write)
                break

    ftp.quit()

# Unzips then deletes a gzip
def ungzipFile(zippedFilename, outputFilename):
    with gzip.open(zippedFilename, "rb") as file_in:
        with open(outputFilename, "wb") as file_out:
            shutil.copyfileobj(file_in,file_out)
    os.remove(zippedFilename)
    

def processXML():
    count = 0
    with open(DATA_OUTPUT_NAME, "r+") as file:
        for line in file:
            count += 1

            # If a <OW> tag appears then Darwin line breaks which breaks up the XML, so this checks we have a properly formed Darwin line.
            if "<Pport" in line and "</Pport>" in line:
                root = et.fromstring(line)

                print(root.keys())
            
                # If TS or Schedule

                    # Should keep a cache of rids kept so that I can check if this rid exists: If not then insert it into list, if it does then nothing.

                    # Add schedule or TS data to database. filed under the rid with a autogenerated primary key.

def job():
    getMostRecentDarwinFile()
    ungzipFile(ZIPPED_OUTPUT_NAME, DATA_OUTPUT_NAME)
    processXML()

    # Cleanup UNCOMMENT FOR FINAL VERSION
    # os.remove(DATA_OUTPUT_NAME)

# Init for testing so that file remains after program execution for inspection
if os.path.isfile(DATA_OUTPUT_NAME):
    os.remove(DATA_OUTPUT_NAME)

endTime = datetime.datetime.now() + datetime.timedelta(minutes=RUNTIME_LENGTH_MINUTES)

while endTime > datetime.datetime.now():
    # Pass off the job to another processor 
    with concurrent.futures.ProcessPoolExecutor(max_workers=1) as executor:
        startTime = datetime.datetime.now()
        future = executor.submit(job)
        endTime = datetime.datetime.now()
        diff = endTime-startTime

    print("finished")
    time.sleep(DARWIN_PULL_INTERVAL)
print("stopped")


